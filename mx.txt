from itertools import combinations

def load_transactions(filename):
    transactions = []
    with open(filename, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) > 1:
                transactions.append(set(parts[1:]))  # skip TID
    return transactions

def support_count(itemset, transactions):
    return sum(1 for t in transactions if itemset.issubset(t))

def dfs_mfi(current_set, items, transactions, min_sup, MFI):
    extended = False
    for i, item in enumerate(items):
        new_set = current_set | {item}
        sup = support_count(new_set, transactions)
        if sup >= min_sup:
            extended = True
            # Recurse on remaining items (to keep lexicographic order)
            dfs_mfi(new_set, items[i+1:], transactions, min_sup, MFI)
    if not extended:
       
        if not any(current_set < mfi for mfi in MFI):
            # Remove any existing MFIs that are subsets of current_set
            MFI[:] = [mfi for mfi in MFI if not (mfi < current_set)]
            MFI.append(current_set)

def find_maximal_frequent_itemsets(filename, min_sup):
    transactions = load_transactions(filename)
    items = sorted({item for t in transactions for item in t})
    MFI = []
    dfs_mfi(set(), items, transactions, min_sup, MFI)
    return MFI

if _name_ == "_main_":
    filename = "td.txt" 
    min_sup = 3       
    MFI = find_maximal_frequent_itemsets(filename, min_sup)
    print(f"Maximal Frequent Itemsets (min_sup={min_sup}):")
    for m in MFI:
        print(sorted(m))